//
//  Created by VT on 16.11.25.
//  Copyright © 2025 Volker Thieme. All rights reserved.
//
//  Permission is hereby granted, free of charge, to any person obtaining a copy
//  of this software and associated documentation files (the "Software"), to deal
//  in the Software without restriction, including without limitation the rights
//  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
//  copies of the Software, and to permit persons to whom the Software is
//  furnished to do so, subject to the following conditions:
//
//  The above copyright notice and this permission notice shall be included in
//  all copies or substantial portions of the Software.
//
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
//  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
//  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
//  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
//  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
//  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
//  THE SOFTWARE.
//  

/// Maximum likelihood fitter for the Geometric distribution in SwiftyStats.

import SwiftyStatsPrelude

extension MLEFitter {
    /// Fits a geometric distribution with support `{0, 1, 2, …}` by maximum likelihood.
    ///
    /// Model
    /// - Let K ~ Geometric(p) with probability mass function
    ///   P(K = k | p) = (1 − p)^k · p for k ∈ {0, 1, 2, …} and p ∈ (0, 1).
    ///
    /// Objective
    /// - Given observations `k₁,…,k_n`, maximize
    ///   ℓ(p) = Σ [ k_i · log(1 − p) + log p ], subject to `p ∈ (0, 1)`.
    ///
    /// Implementation details
    /// - The parameter constraint `p ∈ (0, 1)` is enforced via the solver’s unit-interval transform
    ///   generated by `makeParamSpecs(for: .geometric, data:)`.
    /// - Per-observation log-pmf and analytic score are delegated to
    ///   `SwiftyBoost.Distribution.Geometric`, and the solver aggregates them.
    /// - Covariance (θ-space) and diagnostics are enabled by default in this wrapper.
    ///
    /// Mathematical note
    /// - For the 0-based geometric, the closed-form MLE is `p̂ = 1 / (1 + ȳ)` where `ȳ` is the sample mean.
    ///   The numerical optimizer should recover this in regular settings.
    ///
    /// - Parameters:
    ///   - data: Non-empty sample of counts. For correctness, each element should be an integer `k ≥ 0`.
    ///           Invalid inputs (e.g., negatives or non-integers) are rejected by the underlying distribution
    ///           and penalized in the objective.
    ///   - optimizer: Local optimizer to use (`.nelderMead`, `.bfgs`, or `.lbfgs`). Default is `.lbfgs`.
    ///   - options: Optional solver options. If `nil`, sensible defaults are used and adjusted to compute
    ///              covariance and enable diagnostics.
    ///
    /// - Returns: An `MLEResult<T>` with:
    ///   - `thetaHat = [p̂]` (the MLE of `p`),
    ///   - `logLik` (maximized log-likelihood),
    ///   - convergence flags and evaluation counts,
    ///   - optional covariance and diagnostics when enabled.
    ///
    /// - Precondition: `data` must be non-empty.
    public static func fitGeometric(
        _ data: [T],
        optimizer: OptimizerKind = .lbfgs,
        options: MLEOptimizationOpts<T>? = nil
    ) -> MLEResult<T> {
        precondition(!data.isEmpty)
        // Parameter specs for Geometric(p) with p ∈ (0, 1).
        let dummy = MLEProblem<T>(data: data, logpdf: { _, _ in 0 }, paramSpecs: [.init(.real, initial: 0)])
        let specs = dummy.makeParamSpecs(for: .geometric, data: data)

        // Log-pmf with domain checks (k ∈ {0,1,2,…}, p ∈ (0,1)).
        let logPDF: @Sendable (T, [T]) -> T = { x, theta in
            let p = theta[0]
            if !(p > .zero && p < T.one) { return T.infinity }
            do {
                return try SwiftyBoost.Distribution.Geometric(probabibilityOfSuccess: p).logPdf(x)
            } catch _ {
                return T.infinity
            }
        }

        // Score (∂/∂p log pmf) for p.
        let gradLogPDF: @Sendable (T, [T]) -> [T] = { x, theta in
            let p = theta[0]
            if !(p > .zero && p < T.one) { return [T.infinity] }
            do {
                let dist: SwiftyBoost.Distribution.Geometric<T> = try SwiftyBoost.Distribution.Geometric(probabibilityOfSuccess: p)
                let g = dist.score(k: x, p: p)
                return [g]
            } catch _ {
                return [T.nan]
            }
        }

        let problem = MLEProblem<T>(data: data, logpdf: logPDF, gradlogpdf: gradLogPDF, paramSpecs: specs)
        var opts = options ?? MLEOptimizationOpts<T>()
        opts.computeCovariance = true
        opts.optimizer = optimizer
        opts.diagnosticsEnabled = true
        return MLESolver.fit(problem, options: opts)
    }
}
